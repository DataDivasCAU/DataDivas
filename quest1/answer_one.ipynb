{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9870f2",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "How has the public perception of anti-vaccine conspiracy via YouTube changed during the last five years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976efdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install spacy\n",
    "\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade scipy --no-cache-dir\n",
    "\n",
    "!{sys.executable} -m pip uninstall numpy -y\n",
    "!{sys.executable} -m pip install numpy==1.24.4 --no-cache-dir\n",
    "\n",
    "!{sys.executable} pip install pandas==1.5.3 --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e77fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e21ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "from collections import Counter\n",
    "from keybert import KeyBERT\n",
    "import re\n",
    "\n",
    "\n",
    "data = pd.read_csv('one.csv')\n",
    "\n",
    "# The next line cleans the data by removing duplicate lines.\n",
    "data.drop_duplicates(inplace = True)\n",
    "\n",
    "data['Published At'] = pd.to_datetime(data['Published At'])\n",
    "\n",
    "time_periods = [\n",
    "    ('2020', '2020-01-01', '2020-12-31'),\n",
    "    ('2021', '2021-01-01', '2021-12-31'),\n",
    "    ('2022', '2022-01-01', '2022-12-31'),\n",
    "    ('2023', '2023-01-01', '2023-12-31'),\n",
    "    ('2024', '2024-01-01', '2024-12-31'),\n",
    "    ('2025', '2025-01-01', '2025-12-31'),\n",
    "]\n",
    "result = {}\n",
    "\n",
    "def extract_keywords(data):\n",
    "    model = KeyBERT()\n",
    "    keywords_list = []\n",
    "\n",
    "    for item in data:\n",
    "        text = str(item)\n",
    "        # Extract single-word keywords\n",
    "        kw_single = model.extract_keywords(text, keyphrase_ngram_range=(1,1))\n",
    "        keywords_list.extend(kw_single)\n",
    "\n",
    "    ignore_words = []\n",
    "\n",
    "    flattened_keywords = [kw for kw, score in keywords_list if kw.lower() not in ignore_words]\n",
    "\n",
    "    keywords_df = pd.DataFrame(Counter(flattened_keywords).items(), columns=[\"words\", \"numbers\"])\n",
    "    frequent_words = keywords_df.loc[keywords_df['numbers'] > 1].sort_values(by='numbers', ascending=False)\n",
    "    return frequent_words\n",
    "\n",
    "for name, start, end in time_periods:\n",
    "    filter = (data['Published At'] >= start) & (data['Published At'] <= end)\n",
    "    filtered = data[filter]\n",
    "\n",
    "    frequent_words = extract_keywords(filtered['TOP 10 comments'].astype(str).tolist())\n",
    "    result[name] = {\n",
    "            'keywords': frequent_words.head(15).to_dict(orient=\"records\")\n",
    "        }\n",
    "\n",
    "with open('answer_one.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(result, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a240a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('answer_one.json', 'r', encoding='utf-8') as file:\n",
    "    keywords = json.load(file)\n",
    "\n",
    "frequencies_all_years = defaultdict(int)\n",
    "\n",
    "for year, content in keywords.items():\n",
    "    for kw in content['keywords']:\n",
    "        keyword = kw[\"words\"]\n",
    "        frequency = int(kw[\"numbers\"])  \n",
    "        frequencies_all_years[keyword] += frequency\n",
    "\n",
    "data = pd.DataFrame(frequencies_all_years.items(), columns=['Keyword', 'Frequency'])\n",
    "data = data.sort_values(by='Frequency', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.barh(data['Keyword'], data['Frequency'], color='green')\n",
    "plt.xlabel('Frequency')\n",
    "plt.title(f'Top keywords')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44879233-21b2-4560-a1db-d7f8a68b6a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
