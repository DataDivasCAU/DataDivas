{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b775ec",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "\"How has the public perception of anti-vaccine conspiracy via YouTube changed during the last five years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99da47",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install spacy\n",
    "\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade scipy --no-cache-dir\n",
    "\n",
    "!{sys.executable} -m pip uninstall numpy -y\n",
    "!{sys.executable} -m pip install numpy==1.24.4 --no-cache-dir\n",
    "\n",
    "    \"!{sys.executable} pip install pandas==1.5.3 --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549c6a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06147952",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import ast\n",
    "from keybert import KeyBERT\n",
    "import re\n",
    "    \n",
    "\n",
    "data = pd.read_csv('one.csv')\n",
    "\n",
    "# The next line cleans the data by removing duplicate lines.\n",
    "data.drop_duplicates(inplace = True)\n",
    "\n",
    "data['Published At'] = pd.to_datetime(data['Published At'])\n",
    "\n",
    "# These are the time periods for the comparison of the top keywords.\n",
    "time_periods = [\n",
    "    ('2020', '2020-01-01', '2020-12-31'),\n",
    "    ('2021', '2021-01-01', '2021-12-31'),\n",
    "    ('2022', '2022-01-01', '2022-12-31'),\n",
    "    ('2023', '2023-01-01', '2023-12-31'),\n",
    "    ('2024', '2024-01-01', '2024-12-31'),\n",
    "    ('2025', '2025-01-01', '2025-12-31'),\n",
    "    ]\n",
    "    \n",
    "result = {}\n",
    "\n",
    "def extract_keywords(data):\n",
    "    model = KeyBERT()  # The LLM keybert is used here to extract the keywords.\n",
    "        keywords_list = []\n",
    "        for item in data:\n",
    "            text = str(item)\n",
    "            # kw_single extracts single-word keywords.\n",
    "            kw_single = model.extract_keywords(text, keyphrase_ngram_range=(1,1))\n",
    "            keywords_list.extend(kw_single)\n",
    "    \n",
    "        ignore_words = []\n",
    "        flattened_keywords = [kw for kw, score in keywords_list if kw.lower() not in ignore_words]\n",
    " \n",
    "        # keywords_df creates a Counter which counts how often words occurs in the texts.\n",
    "        keywords_df = pd.DataFrame(Counter(flattened_keywords).items(), columns=[\\\"words\\\", \\\"numbers\\\"])\n",
    "        frequent_words = keywords_df.loc[keywords_df['numbers']].sort_values(by='numbers', ascending=False)\n",
    "        return frequent_words\n",
    "\n",
    "    for name, start, end in time_periods:\n",
    "        filter = (data['Published At'] >= start) & (data['Published At'] <= end)\n",
    "        filtered = data[filter]\n",
    "\n",
    "        frequent_words = extract_keywords(filtered['TOP 10 comments'].astype(str).tolist())\n",
    "        result[name] = {\n",
    "               'keywords': frequent_words.head(15).to_dict(orient=\\\"records\\\")  # The 15 most used words are added to the result.\n",
    "        }\n",
    "with open('answer_one.json', 'w', encoding='utf-8') as file:\n",
    "json.dump(result, file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
