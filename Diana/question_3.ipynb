{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f07853c-ee94-4930-b02e-6dc45c756867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e0bbf14-7ae2-49e7-b061-6ae386674ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IXDdxrJoY0k', 'ynwIZIdsb7w', '43nxknUKiIg', 'Rb-jAqMhem8', '6bQdK4Ok7qc', 'qbR5rWQQlYA', 'e1O4_Ns3ICQ', '-rsHwf56S3s', 'nopHNQfxJ8I', 'UKrhpgeQScg']\n",
      "\n",
      "\n",
      "[[], ['Well done Franziska! Fellow climate striker hereğŸ˜Š', 'Brevity is the soul of wit...a big thank you ğŸ˜ğŸ˜ğŸ˜'], ['Lets fight for Future together!', 'Great initiative .'], ['GroÃŸes Lob an Quarks fÃ¼r die Plattform!!', 'Wenn sich das Bildungsministerium doch nur gleich sehr Ã¼ber die Fehlstunden durch Lehrermangel aufregen wÃ¼rden! Und einen film 2 Stunden anzusehen zÃ¤hlt nicht!!!'], ['Great effort. thanks', 'Sehr erfolgreich das Video...'], [], ['Awesome song and recording job. So overjoyed to find other musicians and kids using their talents and passions to stop <a href=\"http://www.youtube.com/results?search_query=%23climatechange\">#ClimateChange</a> .  This was very motivating. I will add this song to my environmental library for other teachers to find!  Best Wishes from across the pond! Annie LynnğŸŒâœŒğŸ¼ğŸ’ğŸ¼ğŸ¶ğŸ’™', 'Change is always possible cause we are unstoppeble. I love this song'], ['Da bekomme ich GÃ¤nsehaut - ein anz starker Beitrag! Ich habe das ZÃ¶gern und diese ganzen WidersprÃ¼che so satt, handeln wir endlichğŸŒâœŒğŸ¼ğŸŒ³ğŸŒˆ', 'Mir kommen die TrÃ¤nen! Es ist so unglaublich was wir geleistet haben und ich bin der festen Ãœberzeugung, daÃŸ wir es auch weiter schaffen. Vielen danke an ALLE, die uns unterstÃ¼tzen. Die Menschen, die auf die Demos kommen, die FFF mit spenden oder anderweitigen Ressourcen unterstÃ¼tzen.  <br><a href=\"http://www.youtube.com/results?search_query=%23allef%C3%BCrsklima\">#AlleFÃ¼rsKlima</a>, der 20.09 wird absolut hammer.'], ['Can we do another like this for the next strike?', '<a href=\"http://www.youtube.com/results?search_query=%23fridaysforfuture\">#fridaysforfuture</a>'], ['Super, wie die Bewegung wÃ¤chst!<br><br>Gema freier fridays for future Parolensong:<br><a href=\"https://www.youtube.com/watch?v=BFCXfqVy4tY\">https://www.youtube.com/watch?v=BFCXfqVy4tY</a>', 'Ihr versuracht mit dem BlÃ¶dsinn mehr CO2 als dass ihr das Klima schÃ¼tzt'], 'FRIDAYS FOR FUTURE - #voteclimate #globalstrike - ZERO EMISSIONS - KLIMAWAHL', 'Why we shouldnâ€™t need a Fridays for Future Movement | Franziska Marhold | TEDxVienna', 'What is Fridays For Future about? (English Trailer)', 'Fridays for Future: Der harte Kampf gegen den Klimawandel | Quarks', 'Fridays For Future + Scientists for Future - Save this world - Charity song', 'fridays for future short film: seven', 'UNITY - Fridays For Future (Musicvideo)', '9 MONATE FRIDAYS FOR FUTURE #allefÃ¼rsklima', 'Fridays for future all around the world !', 'Fridays for Future World']\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "api_key = \"AIzaSyB9aZe9ZVWhT_RMifZx7SNAHCZLXasG9ug\"\n",
    "youtube = build(\"youtube\", \"v3\", developerKey= api_key)\n",
    "\n",
    "# Setting parameters for video search\n",
    "request = youtube.search().list(\n",
    "    q= \"Fridays for Future\", \n",
    "    maxResults= 10, part=\"snippet\", \n",
    "    order=\"relevance\", \n",
    "    regionCode=\"DE\",\n",
    "    type =\"video\",\n",
    "    publishedAfter=\"2018-01-01T00:00:00Z\",\n",
    "    publishedBefore=\"2020-01-01T00:00:00Z\"\n",
    ")\n",
    "\n",
    "\n",
    "data = request.execute()\n",
    "\n",
    "#List of video ids\n",
    "ids =[]\n",
    "for item in data[\"items\"]:\n",
    "    ids.append(item[\"id\"][\"videoId\"])\n",
    "print(ids)\n",
    "\n",
    "#getting comments for each video\n",
    "all_comments = [] \n",
    "for videoid in ids:\n",
    "    video_comments = []\n",
    "    try: \n",
    "      request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId= videoid,\n",
    "        maxResults= 2,\n",
    "        order= \"relevance\"\n",
    "          \n",
    "    )\n",
    "      response = request.execute()\n",
    "      for c in response.get(\"items\", []):\n",
    "         video_comments.append(c[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"])\n",
    "          \n",
    "    #Comments disabled\n",
    "    except Exception as e:\n",
    "        print()\n",
    "    all_comments.append(video_comments)\n",
    "    \n",
    "#print(all_comments)\n",
    "\n",
    "titles =[]\n",
    "for item in data[\"items\"]:\n",
    "    titles.append(item[\"snippet\"][\"title\"])\n",
    "\n",
    "    \n",
    "final_data = all_comments + titles\n",
    "#print(final_data)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9bfa60d9-af8b-4f1a-b8f8-82f37a739586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keybert in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from keybert) (2.3.2)\n",
      "Requirement already satisfied: rich>=10.4.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from keybert) (14.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from keybert) (1.7.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from keybert) (5.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from rich>=10.4.0->keybert) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from rich>=10.4.0->keybert) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.6.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.56.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (2.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\momok\\.virtualenvs\\momok-1tyo14bv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d98264a-5cb2-46ba-9987-6c376cb51f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        words  numbers\n",
      "33                    fridays       14\n",
      "34                     future       11\n",
      "37             fridays future        8\n",
      "59                      world        5\n",
      "25  (fridaysforfuture, 0.639)        2\n",
      "24           (strike, 0.6042)        2\n",
      "30                  klimawahl        2\n",
      "31                  emissions        2\n",
      "49                klimawandel        2\n",
      "72                 musicvideo        2\n",
      "73                      unity        2\n",
      "76              allefÃ¼rsklima        2\n",
      "77                     monate        2\n",
      "80               future world        2\n"
     ]
    }
   ],
   "source": [
    "# Uses keybert keywords\n",
    "import keybert\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(final_data)\n",
    "model = keybert.KeyBERT()\n",
    "keywords_list = []\n",
    "for item in final_data:\n",
    "    keywords = []\n",
    "    keywords.append(model.extract_keywords(item, keyphrase_ngram_range=(1,1)))\n",
    "    keywords.append(model.extract_keywords(item, keyphrase_ngram_range=(1,2)))\n",
    "    keywords_list.append(keywords)\n",
    "\n",
    "results_df['keywords'] = keywords_list\n",
    "def flatten(xss):\n",
    "    '''returns flattened list of keywords\n",
    "    i: list of lists'''\n",
    "    return [x for xs in xss for x in xs]\n",
    "    \n",
    "flattened_keywords = flatten(flatten(keywords_list))\n",
    "flattened_keywords = [item[0] for item in flattened_keywords]\n",
    "\n",
    "keywords_df = pd.DataFrame()\n",
    "keywords_df['words'] = Counter(flattened_keywords).keys()\n",
    "keywords_df['numbers'] = Counter(flattened_keywords).values()\n",
    "frequent_words = keywords_df.loc[keywords_df['numbers'] > 1].sort_values(by='numbers', ascending=False)\n",
    "print(frequent_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7505751-4108-4ebc-920c-e3f83adc6fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m all_words =[]\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m final_data:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     words= \u001b[43mi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m().split()\n\u001b[32m      6\u001b[39m     all_words.extend(words)\n\u001b[32m      8\u001b[39m cnt= Counter(all_words)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "#This is only counting the most frequent words in the titles (need to flatten)\n",
    "from collections import Counter\n",
    "all_words =[]\n",
    "for i in final_data:\n",
    "    words= i.lower().split()\n",
    "    all_words.extend(words)\n",
    "       \n",
    "cnt= Counter(all_words)\n",
    "\n",
    "for word, count in cnt.items():\n",
    "    if count > 1:\n",
    "        print(word, count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be73d5-8894-4f28-a142-e23a909b8ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
