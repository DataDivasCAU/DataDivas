{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c6db49-8d6a-4f8d-b0c5-bbb409c38e6d",
   "metadata": {},
   "source": [
    "## In what ways has social media contributed to the growth and visibility of the Fridays for Future climate movement?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bbf14-7ae2-49e7-b061-6ae386674ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from collections import OrderedDict\n",
    "api_key = \"\"\n",
    "youtube = build(\"youtube\", \"v3\", developerKey= api_key)\n",
    "\n",
    "# Setting parameters for video search\n",
    "all_videos = []\n",
    "next_page_token = None\n",
    "max_pages = 3\n",
    "current_page = 0\n",
    "\n",
    "while current_page < max_pages:\n",
    "    request = youtube.search().list(\n",
    "        q=\"Fridays for Future\",\n",
    "        maxResults=50,\n",
    "        part=\"snippet\",\n",
    "        order=\"relevance\",\n",
    "        regionCode=\"DE\",\n",
    "        type=\"video\",\n",
    "        publishedAfter=\"2018-01-01T00:00:00Z\",\n",
    "        publishedBefore=\"2021-01-01T00:00:00Z\",\n",
    "        pageToken=next_page_token\n",
    "    )\n",
    "    response = request.execute()\n",
    "    all_videos.extend(response[\"items\"])\n",
    "\n",
    "    next_page_token = response.get(\"nextPageToken\")\n",
    "    current_page += 1\n",
    "    \n",
    "#List of video ids\n",
    "ids = []\n",
    "for item in all_videos:\n",
    "    ids.append(item[\"id\"][\"videoId\"])\n",
    "\n",
    "#handle duplicates \n",
    "unique_ids= list(set(ids))\n",
    "print(unique_ids)\n",
    "\n",
    "titles = []\n",
    "for item in all_videos:\n",
    "    titles.append(item[\"snippet\"][\"title\"])\n",
    "    \n",
    "\n",
    "#getting comments for each video\n",
    "all_comments = [] \n",
    "for videoid in unique_ids:\n",
    "    video_comments = []\n",
    "    try: \n",
    "      request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId= videoid,\n",
    "        maxResults= 10,\n",
    "        testFormat=\"plainText\",\n",
    "        order= \"relevance\"        \n",
    "    )\n",
    "      response = request.execute()\n",
    "      for c in response.get(\"items\", []):\n",
    "         video_comments.append(c[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"])\n",
    "          \n",
    "    #Comments disabled\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    all_comments.append(video_comments)\n",
    "\n",
    "descriptions =[]\n",
    "for video_id in unique_ids:\n",
    "    try:\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        for item in response.get(\"items\", []):\n",
    "            description = item[\"snippet\"].get(\"description\", \"\")\n",
    "            descriptions.append(description)\n",
    "\n",
    "    except Exception as e:\n",
    "         continue\n",
    "        \n",
    "final_data = all_comments + titles + descriptions\n",
    "print(final_data)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86544b-3807-4223-a4fe-4ecead52e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = []\n",
    "\n",
    "for item in unique_ids:\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet, statistics\",\n",
    "        id=item\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for video in response.get(\"items\", []):\n",
    "        title = video[\"snippet\"].get(\"title\", \"\")\n",
    "        stats = video.get(\"statistics\", {})\n",
    "        views = int(stats.get(\"viewCount\", 0))\n",
    "        likes = int(stats.get(\"likeCount\", 0))\n",
    "        comments = int(stats.get(\"commentCount\", 0))\n",
    "        upload_time = video[\"snippet\"].get(\"publishedAt\", \"\")\n",
    "        \n",
    "        video_data.append({\n",
    "            \"title\": title,\n",
    "            \"views\": views,\n",
    "            \"likes\": likes,\n",
    "            \"comments\": comments,\n",
    "            \"upload time\": upload_time\n",
    "            \n",
    "        })\n",
    "\n",
    "#Sort by view count\n",
    "sorted_videos = sorted(video_data, key=lambda x: x['views'], reverse=True)\n",
    "\n",
    "for item in sorted_videos:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe45b9-2511-45f9-afcf-36702a9ed749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Counts how many videos were uploaded on each day\n",
    "df[\"upload time\"] = pd.to_datetime(df[\"upload time\"])\n",
    "df[\"year_month\"] = df[\"upload time\"].dt.to_period(\"M\")\n",
    "video_counts = df[\"year_month\"].value_counts().sort_index()\n",
    "\n",
    "print(video_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98264a-5cb2-46ba-9987-6c376cb51f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "keywords_list = []\n",
    "for item in final_data:\n",
    "    # Handles comments being lists\n",
    "    text = str(item)\n",
    "    kw_single = model.extract_keywords(text, keyphrase_ngram_range=(1,1))\n",
    "    kw_double = model.extract_keywords(text, keyphrase_ngram_range=(1,2))\n",
    "    keywords_list.extend(kw_single + kw_double)\n",
    "\n",
    "# Extract keywords\n",
    "ignore_words = [\"fridays\", \"fridays future\", \"future\", \"fridaysforfuture\", \"auf\", \"thunberg\",\"ich\", \"nicht\", \"greta\", \"klima\", \"und\"]\n",
    "flattened_keywords = [kw for kw, score in keywords_list if kw.lower() not in ignore_words]\n",
    "\n",
    "\n",
    "# Count frequencies\n",
    "keywords_df = pd.DataFrame(Counter(flattened_keywords).items(), columns=[\"words\", \"numbers\"])\n",
    "frequent_words = keywords_df.loc[keywords_df['numbers'] > 1].sort_values(by='numbers', ascending=False)\n",
    "print(frequent_words.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7505751-4108-4ebc-920c-e3f83adc6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be73d5-8894-4f28-a142-e23a909b8ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35581318-0975-4d78-812c-74451823a92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
